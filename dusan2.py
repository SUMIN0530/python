import os
import pandas as pd
import numpy as np
import xgboost as xgb
import lightgbm as lgb
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import PredefinedSplit
import matplotlib.pyplot as plt
from matplotlib import rc

'''
í˜œì˜ì´ê°€ ë³´ë‚´ì¤€ ì½”ë“œ
'''

# í•œê¸€ í°íŠ¸ ì„¤ì •
rc('font', family='Malgun Gothic')
plt.rcParams['axes.unicode_minus'] = False

base_path = r"C:\Users\bhy10\Documents\PYTHONKDT\Update_set"

# =========================
# ë°ì´í„° ë¡œë”©
# =========================


def load_data():
    files = [os.path.join(base_path, "ë‘ì‚°ì—”ì§„MGíƒœì–‘ê´‘_1",
                          f"ë‘ì‚°ì—”ì§„MGíƒœì–‘ê´‘_1_{year}_data.xlsx") for year in range(22, 26)]
    dfs = [pd.read_excel(f) for f in files]
    df = pd.concat(dfs, ignore_index=True)
    df['ì¼ì‹œ'] = pd.to_datetime(df['ì¼ì‹œ'], errors='coerce')
    return df

# =========================
# ë‚ ì§œ/lag/rolling íŠ¹ì„±
# =========================


def add_date_and_lag_features(df):
    df = df.copy().sort_values('ì¼ì‹œ').reset_index(drop=True)
    df['year'] = df['ì¼ì‹œ'].dt.year
    df['month'] = df['ì¼ì‹œ'].dt.month
    df['day'] = df['ì¼ì‹œ'].dt.day
    df['dayofweek'] = df['ì¼ì‹œ'].dt.dayofweek
    df['dayofyear'] = df['ì¼ì‹œ'].dt.dayofyear
    df['season'] = ((df['month'] % 12 + 3) // 3)  # ê³„ì ˆ

    # ì£¼ê¸°í˜• ë³€í™˜
    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
    df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)
    df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)

    # lag & rolling (1,3,7,14)
    cols = ['ì´ëŸ‰(KWh)', 'í‰ê· ê¸°ì˜¨(Â°C)', 'í•©ê³„ ì¼ì‚¬ëŸ‰(MJ/m2)', 'í‰ê·  í’ì†(m/s)', 'í‰ê·  ìƒëŒ€ìŠµë„(%)']
    for col in cols:
        for lag in [1, 3, 7, 14]:
            df[f'{col}_lag{lag}'] = df[col].shift(lag)
        for window in [3, 7, 14]:
            df[f'{col}_rolling{window}'] = df[col].rolling(
                window=window, min_periods=1).mean()

    df = df.dropna().reset_index(drop=True)
    return df

# =========================
# ì§€í‘œ í•¨ìˆ˜
# =========================


def mean_absolute_percentage_error(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    mask = y_true != 0
    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100


def smape(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    denom = (np.abs(y_true) + np.abs(y_pred)) / 2
    mask = denom != 0
    return np.mean(np.abs(y_true[mask] - y_pred[mask]) / denom[mask]) * 100

# =========================
# í•™ìŠµ / ê²€ì¦ / í…ŒìŠ¤íŠ¸ + ì•™ìƒë¸” + ê°€ì¤‘ì¹˜ ìµœì í™”
# =========================


def train_test_ensemble(df):
    df = add_date_and_lag_features(df)

    # 0ê°’ ì²˜ë¦¬
    for col in ['í•©ê³„ ì¼ì‚¬ëŸ‰(MJ/m2)', 'í‰ê· ê¸°ì˜¨(Â°C)', 'í‰ê·  í’ì†(m/s)', 'í‰ê·  ìƒëŒ€ìŠµë„(%)', 'ì´ëŸ‰(KWh)']:
        if col in df.columns:
            df[col] = df[col].replace(0, np.nan).fillna(df[col].mean())

    df['ì „ì¼_ë°œì „ëŸ‰'] = df['ì´ëŸ‰(KWh)'].shift(1).fillna(method='bfill')

    features = [c for c in df.columns if c not in [
        'ì¼ì‹œ', 'ì´ëŸ‰(KWh)'] and df[c].dtype != 'object']

    train = df[df['year'].isin([2022, 2023])].reset_index(drop=True)
    val = df[df['year'] == 2024].reset_index(drop=True)
    test = df[df['year'] == 2025].reset_index(drop=True)

    X_train, y_train = train[features], train['ì´ëŸ‰(KWh)']
    X_val, y_val = val[features], val['ì´ëŸ‰(KWh)']
    X_test, y_test = test[features], test['ì´ëŸ‰(KWh)']

    # ìŠ¤ì¼€ì¼ë§
    scaler_X, scaler_y = MinMaxScaler(), MinMaxScaler()
    X_train_scaled = scaler_X.fit_transform(X_train)
    X_val_scaled = scaler_X.transform(X_val)
    X_test_scaled = scaler_X.transform(X_test)
    y_train_scaled = scaler_y.fit_transform(
        y_train.values.reshape(-1, 1)).ravel()
    y_val_scaled = scaler_y.transform(y_val.values.reshape(-1, 1)).ravel()

    X_total = np.vstack([X_train_scaled, X_val_scaled])
    y_total = np.concatenate([y_train_scaled, y_val_scaled])

    # ===== XGBoost ìµœì  ì„¤ì • =====
    best_xgb = xgb.XGBRegressor(
        subsample=0.7,
        reg_lambda=1,
        reg_alpha=0,
        n_estimators=500,
        min_child_weight=5,
        max_depth=7,
        learning_rate=0.05,
        gamma=0,
        colsample_bytree=0.9,
        random_state=42,
        tree_method='hist'
    )
    best_xgb.fit(X_total, y_total)

    # ===== LightGBM ìµœì  ì„¤ì • =====
    best_lgb = lgb.LGBMRegressor(
        subsample=0.7,
        reg_lambda=1,
        reg_alpha=0,
        n_estimators=700,
        max_depth=7,
        learning_rate=0.01,
        colsample_bytree=0.8,
        random_state=42
    )
    best_lgb.fit(X_total, y_total)

    # ===== ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ =====
    y_pred_xgb = scaler_y.inverse_transform(
        best_xgb.predict(X_test_scaled).reshape(-1, 1)).ravel()
    y_pred_lgb = scaler_y.inverse_transform(
        best_lgb.predict(X_test_scaled).reshape(-1, 1)).ravel()
    y_test = y_test.values

    # ===== ê°€ì¤‘ì¹˜ ìµœì í™” =====
    best_weight, best_r2, best_metrics = None, -np.inf, None
    results_list = []

    mask_test = y_test > 5
    for w in np.arange(0, 1.05, 0.05):
        y_ensemble = w * y_pred_xgb + (1 - w) * y_pred_lgb
        metrics = {
            'XGB_Weight': round(w, 2),
            'LGB_Weight': round(1 - w, 2),
            'MAE': mean_absolute_error(y_test[mask_test], y_ensemble[mask_test]),
            'RMSE': np.sqrt(mean_squared_error(y_test[mask_test], y_ensemble[mask_test])),
            'R2': r2_score(y_test[mask_test], y_ensemble[mask_test]),
            'MAPE': mean_absolute_percentage_error(y_test[mask_test], y_ensemble[mask_test]),
            'SMAPE': smape(y_test[mask_test], y_ensemble[mask_test])
        }
        results_list.append(metrics)
        if metrics['R2'] > best_r2:
            best_r2, best_weight, best_metrics = metrics['R2'], w, metrics

    df_results = pd.DataFrame(results_list)
    print("\nğŸ’¡ ìµœì  ê°€ì¤‘ì¹˜ (RÂ² ê¸°ì¤€): XGB={:.2f}, LGB={:.2f}, RÂ²={:.4f}".format(
        best_metrics['XGB_Weight'], best_metrics['LGB_Weight'], best_metrics['R2']))
    print("\nê°€ì¤‘ì¹˜ë³„ ì„±ëŠ¥ ë³€í™”í‘œ:")
    print(df_results)

    # ===== ê²°ê³¼ ì €ì¥ =====
    save_path = os.path.join(base_path, "ë‘ì‚°ì—”ì§„MGíƒœì–‘ê´‘_1")
    os.makedirs(save_path, exist_ok=True)
    df_results.to_excel(os.path.join(
        save_path, "ensemble_weight_optimization.xlsx"), index=False)

    return best_xgb, best_lgb, df_results, best_metrics


# =========================
# ì‹¤í–‰
# =========================
df_data = load_data()
best_xgb, best_lgb, df_results, best_metrics = train_test_ensemble(df_data)
