import os
import pandas as pd
import numpy as np
import xgboost as xgb
import lightgbm as lgb
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import RandomizedSearchCV, PredefinedSplit
import matplotlib.pyplot as plt
from matplotlib import rc
'''XGBoost, Light BGM ì•™ìƒë¸” 1:1 ì–´ì©Œê³  ì˜ˆì¸¡ê°’ê³¼ ê¸°íƒ€ ë“±ë“± êµ¬í•¨ + ê·¸ë˜í”„'''
# í•œê¸€ í°íŠ¸
rc('font', family='Malgun Gothic')
plt.rcParams['axes.unicode_minus'] = False

# =========================
# íŒŒì¼ ê²½ë¡œ
# =========================
base_path = r"C:\Users\alsl0\Documents\python\Update_set"

# =========================
# ë°ì´í„° ë¡œë”©
# =========================

name = 'ì˜ˆì²œíƒœì–‘ê´‘_1'


def load_data():
    files = [os.path.join(base_path, f"{name}",
                          f"{name}_{year}_data.xlsx") for year in range(22, 26)]
    dfs = [pd.read_excel(f) for f in files]
    df = pd.concat(dfs, ignore_index=True)
    df['ì¼ì‹œ'] = pd.to_datetime(df['ì¼ì‹œ'], errors='coerce')
    return df

# =========================
# ë‚ ì§œ, lag, rolling ìƒì„±
# =========================


def add_date_and_lag_features(df):
    df = df.copy().sort_values('ì¼ì‹œ').reset_index(drop=True)
    df['year'] = df['ì¼ì‹œ'].dt.year
    df['month'] = df['ì¼ì‹œ'].dt.month
    df['day'] = df['ì¼ì‹œ'].dt.day
    df['dayofweek'] = df['ì¼ì‹œ'].dt.dayofweek
    df['dayofyear'] = df['ì¼ì‹œ'].dt.dayofyear
    df['season'] = ((df['month'] % 12 + 3)//3)

    # ì£¼ê¸°í˜• ë³€í™˜
    df['month_sin'] = np.sin(2*np.pi*df['month']/12)
    df['month_cos'] = np.cos(2*np.pi*df['month']/12)
    df['dayofweek_sin'] = np.sin(2*np.pi*df['dayofweek']/7)
    df['dayofweek_cos'] = np.cos(2*np.pi*df['dayofweek']/7)

    # lag, rolling
    for col in ['ì´ëŸ‰(KWh)', 'í‰ê· ê¸°ì˜¨(Â°C)', 'í•©ê³„ ì¼ì‚¬ëŸ‰(MJ/m2)', 'í‰ê·  í’ì†(m/s)', 'í‰ê·  ìƒëŒ€ìŠµë„(%)']:
        for lag in [1, 3, 7, 14]:
            df[f'{col}_lag{lag}'] = df[col].shift(lag)
        for window in [3, 7, 14]:
            df[f'{col}_rolling{window}'] = df[col].rolling(
                window=window, min_periods=1).mean()

    df = df.dropna().reset_index(drop=True)
    return df

# =========================
# ì§€í‘œ í•¨ìˆ˜
# =========================


def mean_absolute_percentage_error(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    mask = y_true != 0
    if mask.sum() == 0:
        return np.nan
    return np.mean(np.abs((y_true[mask]-y_pred[mask])/y_true[mask]))*100


def smape(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    denom = (np.abs(y_true)+np.abs(y_pred))/2
    mask = denom != 0
    if mask.sum() == 0:
        return np.nan
    return np.mean(np.abs(y_true[mask]-y_pred[mask])/denom[mask])*100

# =========================
# í•™ìŠµ / í‰ê°€ / ìµœì  ê°€ì¤‘ì¹˜
# =========================


def train_test_optimal_ensemble(df, n_iter_search=50):
    df = add_date_and_lag_features(df)

    # ê²°ì¸¡/0 ì²˜ë¦¬
    for col in ['í•©ê³„ ì¼ì‚¬ëŸ‰(MJ/m2)', 'í‰ê· ê¸°ì˜¨(Â°C)', 'í‰ê·  í’ì†(m/s)', 'í‰ê·  ìƒëŒ€ìŠµë„(%)', 'ì´ëŸ‰(KWh)']:
        if col in df.columns:
            df[col] = df[col].replace(0, np.nan).fillna(df[col].mean())

    df['ì „ì¼_ë°œì „ëŸ‰'] = df['ì´ëŸ‰(KWh)'].shift(1).fillna(method='bfill')

    features = [c for c in df.columns if c not in [
        'ì¼ì‹œ', 'ì´ëŸ‰(KWh)'] and df[c].dtype != 'object']

    # ë°ì´í„° ë¶„ë¦¬
    train = df[df['year'].isin([2022, 2023])]
    val = df[df['year'] == 2024]
    test = df[df['year'] == 2025]

    X_train, y_train = train[features], train['ì´ëŸ‰(KWh)']
    X_val, y_val = val[features], val['ì´ëŸ‰(KWh)']
    X_test, y_test = test[features], test['ì´ëŸ‰(KWh)']

    # ìŠ¤ì¼€ì¼ë§
    scaler_X, scaler_y = MinMaxScaler(), MinMaxScaler()
    X_train_scaled = scaler_X.fit_transform(X_train)
    X_val_scaled = scaler_X.transform(X_val)
    X_test_scaled = scaler_X.transform(X_test)
    y_train_scaled = scaler_y.fit_transform(
        y_train.values.reshape(-1, 1)).ravel()
    y_val_scaled = scaler_y.transform(y_val.values.reshape(-1, 1)).ravel()

    # PredefinedSplit
    X_total = np.vstack([X_train_scaled, X_val_scaled])
    y_total = np.concatenate([y_train_scaled, y_val_scaled])
    ps = PredefinedSplit(
        test_fold=[-1]*len(X_train_scaled) + [0]*len(X_val_scaled))

    # =========================
    # XGBoost
    # =========================
    xgb_model = xgb.XGBRegressor(
        random_state=42, eval_metric='rmse', tree_method='hist')
    param_dist_xgb = {
        'n_estimators': [500, 700, 1000],
        'max_depth': [3, 5, 7],
        'learning_rate': [0.01, 0.05, 0.1],
        'subsample': [0.7, 0.8, 0.9],
        'colsample_bytree': [0.7, 0.8, 0.9],
        'gamma': [0, 0.1, 0.3],
        'min_child_weight': [1, 3, 5],
        'reg_alpha': [0, 0.5, 1],
        'reg_lambda': [1, 1.2]
    }

    rs_xgb = RandomizedSearchCV(xgb_model, param_distributions=param_dist_xgb, n_iter=n_iter_search,
                                cv=ps, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=1, random_state=None)
    rs_xgb.fit(X_total, y_total)
    best_xgb = rs_xgb.best_estimator_

    # =========================
    # LightGBM
    # =========================
    lgb_model = lgb.LGBMRegressor(random_state=42)
    param_dist_lgb = {
        'n_estimators': [500, 700, 1000],
        'max_depth': [3, 5, 7],
        'learning_rate': [0.01, 0.05, 0.1],
        'subsample': [0.7, 0.8, 0.9],
        'colsample_bytree': [0.7, 0.8, 0.9],
        'reg_alpha': [0, 0.5, 1],
        'reg_lambda': [1, 1.2]
    }

    rs_lgb = RandomizedSearchCV(lgb_model, param_distributions=param_dist_lgb, n_iter=n_iter_search,
                                cv=ps, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=1, random_state=None)
    rs_lgb.fit(X_total, y_total)
    best_lgb = rs_lgb.best_estimator_

    print("âœ… XGBoost ìµœì  íŒŒë¼ë¯¸í„°:", rs_xgb.best_params_)
    print("âœ… LightGBM ìµœì  íŒŒë¼ë¯¸í„°:", rs_lgb.best_params_)

    # =========================
    # ê²€ì¦ì…‹ ê¸°ë°˜ ìµœì  ê°€ì¤‘ì¹˜ íƒìƒ‰
    # =========================
    y_pred_val_xgb = scaler_y.inverse_transform(
        best_xgb.predict(X_val_scaled).reshape(-1, 1)).ravel()
    y_pred_val_lgb = scaler_y.inverse_transform(
        best_lgb.predict(X_val_scaled).reshape(-1, 1)).ravel()

    best_rmse, best_w = float('inf'), 0
    for w in np.linspace(0, 1, 101):
        y_ens_val = w*y_pred_val_xgb + (1-w)*y_pred_val_lgb
        rmse = np.sqrt(mean_squared_error(y_val, y_ens_val))
        if rmse < best_rmse:
            best_rmse, best_w = rmse, w

    print(f"ğŸŒŸ ìµœì  ì•™ìƒë¸” ê°€ì¤‘ì¹˜: XGB={best_w:.2f}, LGB={1-best_w:.2f}")

    # =========================
    # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
    # =========================
    y_pred_xgb = scaler_y.inverse_transform(
        best_xgb.predict(X_test_scaled).reshape(-1, 1)).ravel()
    y_pred_lgb = scaler_y.inverse_transform(
        best_lgb.predict(X_test_scaled).reshape(-1, 1)).ravel()
    y_test_pred = best_w*y_pred_xgb + (1-best_w)*y_pred_lgb

    # =========================
    # í‰ê°€
    # =========================
    mask = y_test > 5
    mae = mean_absolute_error(y_test[mask], y_test_pred[mask])
    rmse = np.sqrt(mean_squared_error(y_val, y_ens_val))
    r2 = r2_score(y_test[mask], y_test_pred[mask])
    mape = mean_absolute_percentage_error(y_test[mask], y_test_pred[mask])
    smape_val = smape(y_test[mask], y_test_pred[mask])

    mean_y = np.mean(y_test[mask])
    mae_pct, rmse_pct = (mae/mean_y)*100, (rmse/mean_y)*100

    results = {
        'MAE(kWh)': round(mae, 4),
        'MAE(%)': round(mae_pct, 4),
        'RMSE(kWh)': round(rmse, 4),
        'RMSE(%)': round(rmse_pct, 4),
        'R2': round(r2, 6),
        'MAPE(%)': round(mape, 4),
        'SMAPE(%)': round(smape_val, 4),
        'ìµœì ê°€ì¤‘ì¹˜_XGB': round(best_w, 4),
        'ìµœì ê°€ì¤‘ì¹˜_LGB': round(1-best_w, 4),
        'XGB_íŒŒë¼ë¯¸í„°': str(rs_xgb.best_params_),
        'LGB_íŒŒë¼ë¯¸í„°': str(rs_lgb.best_params_)
    }

    print("ğŸ“Š 2025ë…„ í…ŒìŠ¤íŠ¸ ê²°ê³¼:", results)

    # =========================
    # ì €ì¥ ë° ì‹œê°í™” (ìˆ˜ì •ë¨)
    # =========================
    save_path = os.path.join(base_path, f"{name}")
    os.makedirs(save_path, exist_ok=True)

    # ğŸ”¹ ì˜ˆì¸¡ê²°ê³¼ ì‹œíŠ¸ êµ¬ì„±
    df_pred = test[['ë°œì „êµ¬ë¶„', 'ì¼ì‹œ', 'ì´ëŸ‰(KWh)']].copy()
    df_pred = df_pred.rename(columns={'ì´ëŸ‰(KWh)': 'ì‹¤ì œê°’'})
    df_pred['ì˜ˆì¸¡ê°’'] = y_test_pred

    # ğŸ”¹ ëª¨ë¸í‰ê°€ ì‹œíŠ¸ êµ¬ì„±
    df_eval = pd.DataFrame([{
        'MAE(kWh)': results['MAE(kWh)'],
        'MAE(%)': results['MAE(%)'],
        'RMSE(kWh)': results['RMSE(kWh)'],
        'RMSE(%)': results['RMSE(%)'],
        'R2': results['R2'],
        'MAPE(%)': results['MAPE(%)'],
        'SMAPE(%)': results['SMAPE(%)'],
        'XGBíŒŒë¼ë¯¸í„°': results['XGB_íŒŒë¼ë¯¸í„°'],
        'LGBíŒŒë¼ë¯¸í„°': results['LGB_íŒŒë¼ë¯¸í„°'],
        'ìµœì ê°€ì¤‘ì¹˜_XGB': results['ìµœì ê°€ì¤‘ì¹˜_XGB'],
        'ìµœì ê°€ì¤‘ì¹˜_LGB': results['ìµœì ê°€ì¤‘ì¹˜_LGB']
    }])

    # ğŸ”¹ í•˜ë‚˜ì˜ ì—‘ì…€ íŒŒì¼ì— ì‹œíŠ¸ 2ê°œ ì €ì¥
    output_path = os.path.join(save_path, "ì˜ˆì¸¡ê²°ê³¼_ë°_ëª¨ë¸í‰ê°€.xlsx")
    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
        df_pred.to_excel(writer, sheet_name='ì˜ˆì¸¡ê²°ê³¼', index=False)
        df_eval.to_excel(writer, sheet_name='ëª¨ë¸í‰ê°€', index=False)

    print(f"ğŸ“ ì—‘ì…€ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")

    # ê·¸ë˜í”„ ìƒì„±
    plt.figure(figsize=(14, 6))
    plt.plot(df_pred['ì¼ì‹œ'], df_pred['ì‹¤ì œê°’'],
             label='ì‹¤ì œê°’', marker='o', linewidth=1)
    plt.plot(df_pred['ì¼ì‹œ'], df_pred['ì˜ˆì¸¡ê°’'],
             label='ì˜ˆì¸¡ê°’', marker='x', linewidth=1)
    plt.title(f"'{name}'' - ìµœì ê°€ì¤‘ì¹˜ ì•™ìƒë¸” ê²°ê³¼")
    plt.xlabel("ì¼ì‹œ")
    plt.ylabel("ë°œì „ëŸ‰(kWh)")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(save_path, "ì˜ˆì¸¡ê²°ê³¼ ê·¸ë˜í”„.png"))
    plt.close()

    # =========================
    # âœ… ì „ì²´ê¸°ê°„(22~25ë…„) ì˜ˆì¸¡ ì¶”ê°€
    # =========================
    X_all_scaled = scaler_X.transform(df[features])
    y_pred_xgb_all = scaler_y.inverse_transform(
        best_xgb.predict(X_all_scaled).reshape(-1, 1)).ravel()
    y_pred_lgb_all = scaler_y.inverse_transform(
        best_lgb.predict(X_all_scaled).reshape(-1, 1)).ravel()
    y_pred_all = best_w*y_pred_xgb_all + (1-best_w)*y_pred_lgb_all

    df_all = df.copy()
    df_all['ì˜ˆì¸¡ê°’'] = y_pred_all
    df_all['ì‹¤ì œê°’'] = df['ì´ëŸ‰(KWh)']

    # =========================
    # âœ… 22~25ë…„ ì „ì²´ ê·¸ë˜í”„ ì¶”ê°€
    # =========================
    plt.figure(figsize=(14, 6))
    plt.plot(df_all['ì¼ì‹œ'], df_all['ì‹¤ì œê°’'], label='ì‹¤ì œ ë°œì „ëŸ‰(kWh)',
             color='tab:blue', linewidth=1.5)
    plt.plot(df_all['ì¼ì‹œ'], df_all['ì˜ˆì¸¡ê°’'], label='ì˜ˆì¸¡ ë°œì „ëŸ‰(kWh)',
             color='tab:orange', linewidth=1.5)
    plt.title("2022.01.01 ~ 2025.08.31 ì‹¤ì œ vs ì˜ˆì¸¡ ë°œì „ëŸ‰ ë¹„êµ", fontsize=13)
    plt.xlabel("ì¼ì‹œ")
    plt.ylabel("ë°œì „ëŸ‰(kWh)")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()

    save_path = os.path.join(base_path, f"{name}")
    plt.savefig(os.path.join(save_path, "ì‹¤ì œ_vs_ì˜ˆì¸¡_ì „ì²´ê¸°ê°„_ê·¸ë˜í”„.png"))
    plt.close()

    print("ğŸ“Š ì „ì²´ ê¸°ê°„(2022~2025) ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ")

    # =========================
    # ê²°ê³¼ ë°˜í™˜
    # =========================
    return best_xgb, best_lgb, y_test_pred


# =========================
# ì‹¤í–‰
# =========================
df_data = load_data()
best_xgb, best_lgb, test_results = train_test_optimal_ensemble(df_data)
