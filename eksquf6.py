import os
import random
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import rc
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import RandomizedSearchCV
import xgboost as xgb
'''MAE, RSME, R^2, MAPE, SMAPE (%)'''
# =============================
# í•œê¸€ í°íŠ¸ ì„¤ì •
# =============================
rc('font', family='Malgun Gothic')
plt.rcParams['axes.unicode_minus'] = False

root_path = r"C:/Users/alsl0/Documents/python/ì§€ì—­ë³„_ë°œì „ëŸ‰_ë¹„êµ"
regions = [d for d in os.listdir(
    root_path) if os.path.isdir(os.path.join(root_path, d))]
print(f"ğŸ“‚ íƒìƒ‰ëœ ì§€ì—­: {regions}")

summary_list = []  # ì „ì²´ ìš”ì•½ ì €ì¥ìš©

# =============================
# ë³´ì¡° í•¨ìˆ˜
# =============================


def MAPE(y_true, y_pred):
    return np.mean(np.abs((y_true - y_pred) / np.clip(y_true, 1e-6, None))) * 100


def SMAPE(y_true, y_pred):
    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-6))


def get_season(month):
    if month in [12, 1, 2]:
        return "ê²¨ìš¸"
    elif month in [3, 4, 5]:
        return "ë´„"
    elif month in [6, 7, 8]:
        return "ì—¬ë¦„"
    else:
        return "ê°€ì„"


# =============================
# ì§€ì—­ë³„ ë°˜ë³µ
# =============================
for region in regions:
    print(f"\n==================== {region} ====================")
    base_path = os.path.join(root_path, region)
    train_files = [
        os.path.join(base_path, "23_train_data.xlsx"),
        os.path.join(base_path, "24_test_data.xlsx")
    ]
    test_path = os.path.join(base_path, "25_test_data.xlsx")

    # í•„ìš”í•œ íŒŒì¼ ì²´í¬
    if not all(os.path.exists(f) for f in train_files) or not os.path.exists(test_path):
        print(f"âš ï¸ {region}: í•„ìš”í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœ€.")
        continue

    # =============================
    # ë°ì´í„° ë¡œë“œ
    # =============================
    train_df = pd.concat([pd.read_excel(f, engine="openpyxl")
                         for f in train_files], ignore_index=True)
    test_df = pd.read_excel(test_path, engine="openpyxl")

    X_train = train_df[['í•©ê³„ ì¼ì‚¬ëŸ‰(MJ/m2)', 'í‰ê· ê¸°ì˜¨(Â°C)']]
    y_train = train_df['ì´ëŸ‰(KWh)']
    X_test = test_df[['í•©ê³„ ì¼ì‚¬ëŸ‰(MJ/m2)', 'í‰ê· ê¸°ì˜¨(Â°C)']]
    y_test = test_df['ì´ëŸ‰(KWh)']
    dates_test = pd.to_datetime(test_df['ì¼ì‹œ'], errors='coerce')

    # =============================
    # ìˆ«ìí˜• ë³€í™˜ & ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    # =============================
    X_train[X_train.columns] = X_train.apply(pd.to_numeric, errors='coerce')
    X_test[X_test.columns] = X_test.apply(pd.to_numeric, errors='coerce')
    y_train = pd.to_numeric(y_train, errors='coerce')
    y_test = pd.to_numeric(y_test, errors='coerce')

    for df in [X_train, X_test]:
        df.replace(0, np.nan, inplace=True)
        df.interpolate(method='linear', inplace=True)
        df.ffill(inplace=True)
        df.bfill(inplace=True)
    y_train = y_train.replace(0, np.nan).interpolate().ffill().bfill()
    y_test_interp = y_test.replace(0, np.nan).interpolate().ffill().bfill()

    # =============================
    # ìŠ¤ì¼€ì¼ë§
    # =============================
    scaler_X, scaler_y = MinMaxScaler(), MinMaxScaler()
    X_train_s = scaler_X.fit_transform(X_train)
    X_test_s = scaler_X.transform(X_test)
    y_train_s = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()

    # =============================
    # XGBoost + RandomizedSearch
    # =============================
    param_grid = {
        'max_depth': [4, 5, 6],
        'learning_rate': [0.01, 0.05, 0.1],
        'n_estimators': [200, 500, 800],
        'gamma': [0, 0.1, 0.3],
        'min_child_weight': [1, 3, 5],
        'subsample': [0.7, 0.8, 1.0],
        'colsample_bytree': [0.7, 0.8, 1.0]
    }
    model = xgb.XGBRegressor(random_state=42, eval_metric='rmse')
    search = RandomizedSearchCV(
        model, param_grid, n_iter=50, scoring='r2', cv=3, n_jobs=-1, verbose=0)
    search.fit(X_train_s, y_train_s)
    best_model = search.best_estimator_

    # =============================
    # ì˜ˆì¸¡
    # =============================
    y_pred_s = best_model.predict(X_test_s)
    y_pred = scaler_y.inverse_transform(y_pred_s.reshape(-1, 1)).ravel()

    # =============================
    # ì „ì²´ ì§€í‘œ ê³„ì‚° (KWh + %)
    # =============================
    mae = mean_absolute_error(y_test_interp, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test_interp, y_pred))
    r2 = r2_score(y_test_interp, y_pred)
    mape = MAPE(y_test_interp, y_pred)
    smape = SMAPE(y_test_interp, y_pred)

    mean_actual = np.mean(y_test_interp)
    mae_pct = mae / mean_actual * 100
    rmse_pct = rmse / mean_actual * 100

    print(f"\n{region} ì „ì²´ ì§€í‘œ:")
    print(f"MAE: {mae:.2f} ({mae_pct:.2f}%), RMSE: {rmse:.2f} ({rmse_pct:.2f}%), RÂ²: {r2:.4f}, MAPE: {mape:.2f}%, SMAPE: {smape:.2f}%")

    # =============================
    # ì›”ë³„Â·ê³„ì ˆë³„ ë¶„ì„
    # =============================
    temp = pd.DataFrame({
        'ì¼ì‹œ': dates_test,
        'ì‹¤ì œë°œì „ëŸ‰': y_test_interp.ravel(),
        'ì˜ˆì¸¡ë°œì „ëŸ‰': y_pred
    })
    temp['ì›”'] = temp['ì¼ì‹œ'].dt.month
    temp['ê³„ì ˆ'] = temp['ì›”'].apply(get_season)

    monthly_stats = temp.groupby('ì›”').apply(lambda g: pd.Series({
        'MAE': mean_absolute_error(g['ì‹¤ì œë°œì „ëŸ‰'], g['ì˜ˆì¸¡ë°œì „ëŸ‰']),
        'MAPE': MAPE(g['ì‹¤ì œë°œì „ëŸ‰'], g['ì˜ˆì¸¡ë°œì „ëŸ‰']),
        'SMAPE': SMAPE(g['ì‹¤ì œë°œì „ëŸ‰'], g['ì˜ˆì¸¡ë°œì „ëŸ‰'])
    })).reset_index()

    seasonal_stats = temp.groupby('ê³„ì ˆ').apply(lambda g: pd.Series({
        'MAE': mean_absolute_error(g['ì‹¤ì œë°œì „ëŸ‰'], g['ì˜ˆì¸¡ë°œì „ëŸ‰']),
        'MAPE': MAPE(g['ì‹¤ì œë°œì „ëŸ‰'], g['ì˜ˆì¸¡ë°œì „ëŸ‰']),
        'SMAPE': SMAPE(g['ì‹¤ì œë°œì „ëŸ‰'], g['ì˜ˆì¸¡ë°œì „ëŸ‰'])
    })).reset_index()

    # =============================
    # ê²°ê³¼ í´ë” ì €ì¥
    # =============================
    result_path = os.path.join(base_path, "ê²°ê³¼")
    os.makedirs(result_path, exist_ok=True)

    with pd.ExcelWriter(os.path.join(result_path, f"{region}_ìƒì„¸ë¶„ì„.xlsx")) as writer:
        temp.to_excel(writer, sheet_name='ì¼ìë³„', index=False)
        monthly_stats.to_excel(writer, sheet_name='ì›”ë³„ë¶„ì„', index=False)
        seasonal_stats.to_excel(writer, sheet_name='ê³„ì ˆë³„ë¶„ì„', index=False)

    plt.figure(figsize=(14, 5))
    plt.plot(temp['ì¼ì‹œ'], temp['ì‹¤ì œë°œì „ëŸ‰'], label='ì‹¤ì œê°’', marker='o', linewidth=1)
    plt.plot(temp['ì¼ì‹œ'], temp['ì˜ˆì¸¡ë°œì „ëŸ‰'], label='ì˜ˆì¸¡ê°’', marker='s', linewidth=1)
    plt.title(f"{region} ì¼ìë³„ ë°œì „ëŸ‰ ì˜ˆì¸¡ ë¹„êµ")
    plt.xlabel('ì¼ì‹œ')
    plt.ylabel('ë°œì „ëŸ‰(KWh)')
    plt.legend()
    plt.tight_layout()
    plt.savefig(os.path.join(result_path, f"{region}_ì˜ˆì¸¡ê·¸ë˜í”„.png"), dpi=300)
    plt.close()

    # =============================
    # ì „ì²´ ìš”ì•½ ì €ì¥
    # =============================
    summary_list.append({
        'ì§€ì—­': region,
        'MAE(KWh)': mae,
        'MAE(%)': mae_pct,
        'RMSE(KWh)': rmse,
        'RMSE(%)': rmse_pct,
        'RÂ²': r2,
        'MAPE(%)': mape,
        'SMAPE(%)': smape,
        'ìµœì íŒŒë¼ë¯¸í„°': str(search.best_params_)
    })

# =============================
# ì „ì²´ ìš”ì•½ ì—‘ì…€ ì €ì¥
# =============================
summary_df = pd.DataFrame(summary_list).sort_values('MAE(KWh)')
summary_path = os.path.join(root_path, "ì „ì²´_ìš”ì•½.xlsx")
summary_df.to_excel(summary_path, index=False)
print(f"\nâœ… ì „ì²´ ì§€ì—­ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {summary_path}")
